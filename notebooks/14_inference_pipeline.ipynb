{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_date=Timestamp('2024-04-15 16:00:00')\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "current_date = pd.to_datetime(datetime.utcnow()).floor('H') # - timedelta(hours=1)\n",
    "print(f'{current_date=}')\n",
    "# current_date = pd.Timestamp('2023-02-28 09:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/571542\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/571542\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Could not establish connection to ArrowFlight Server. (Flight returned timeout error, with message: Deadline Exceeded) Will fall back to hive/spark for this session. If the error persists, you can disable using ArrowFlight by changing the cluster configuration (set 'enable_flyingduck'='false').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hive (94.30s) \n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Time-series data is not complete. Make sure your feature pipeline is up and runnning.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_batch_of_features_from_store\n\u001b[1;32m----> 3\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mload_batch_of_features_from_store\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_date\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\ML System\\Taxi_Demand_Predictor\\src\\inference.py:73\u001b[0m, in \u001b[0;36mload_batch_of_features_from_store\u001b[1;34m(current_date)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# validate we are not missing data in the feature store\u001b[39;00m\n\u001b[0;32m     72\u001b[0m location_ids \u001b[38;5;241m=\u001b[39m ts_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpickup_location_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m---> 73\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ts_data) \u001b[38;5;241m==\u001b[39m config\u001b[38;5;241m.\u001b[39mN_FEATURES \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(location_ids), \\\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime-series data is not complete. Make sure your feature pipeline is up and runnning.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# transpose time-series data as a feature vector, for each `pickup_location_id`\u001b[39;00m\n\u001b[0;32m     77\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mlen\u001b[39m(location_ids), n_features), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Time-series data is not complete. Make sure your feature pipeline is up and runnning."
     ]
    }
   ],
   "source": [
    "from src.inference import load_batch_of_features_from_store\n",
    "\n",
    "features = load_batch_of_features_from_store(current_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/571542\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Downloading model artifact (0 dirs, 3 files)... DONE\r"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     load_model_from_registry,\n\u001b[0;32m      3\u001b[0m     get_model_predictions\n\u001b[0;32m      4\u001b[0m )\n\u001b[0;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m load_model_from_registry()\n\u001b[1;32m----> 7\u001b[0m predictions \u001b[38;5;241m=\u001b[39m get_model_predictions(model, \u001b[43mfeatures\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "from src.inference import (\n",
    "    load_model_from_registry,\n",
    "    get_model_predictions\n",
    ")\n",
    "\n",
    "model = load_model_from_registry()\n",
    "predictions = get_model_predictions(model, features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>predicted_demand</th>\n",
       "      <th>pickup_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-03-24 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-03-24 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-03-24 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2024-03-24 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-03-24 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>261</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2024-03-24 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>262</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2024-03-24 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>263</td>\n",
       "      <td>121.0</td>\n",
       "      <td>2024-03-24 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>264</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2024-03-24 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>265</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2024-03-24 11:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pickup_location_id  predicted_demand         pickup_hour\n",
       "0                     1               1.0 2024-03-24 11:00:00\n",
       "1                     2               0.0 2024-03-24 11:00:00\n",
       "2                     3               0.0 2024-03-24 11:00:00\n",
       "3                     4               4.0 2024-03-24 11:00:00\n",
       "4                     5               0.0 2024-03-24 11:00:00\n",
       "..                  ...               ...                 ...\n",
       "255                 261              36.0 2024-03-24 11:00:00\n",
       "256                 262             101.0 2024-03-24 11:00:00\n",
       "257                 263             121.0 2024-03-24 11:00:00\n",
       "258                 264              50.0 2024-03-24 11:00:00\n",
       "259                 265               3.0 2024-03-24 11:00:00\n",
       "\n",
       "[260 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions['pickup_hour'] = current_date\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/571542\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "from src.feature_store_api import get_feature_store\n",
    "import src.config as config\n",
    "\n",
    "# connect to the feature group\n",
    "feature_group = get_feature_store().get_or_create_feature_group(\n",
    "    name=config.FEATURE_GROUP_MODEL_PREDICTIONS,\n",
    "    version=1,\n",
    "    description=\"Predictions generate by our production model\",\n",
    "    primary_key = ['pickup_location_id', 'pickup_hour'],\n",
    "    event_time='pickup_hour',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4ef32de9094897acfe07839c89926c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/260 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: model_predictions_feature_group_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/571542/jobs/named/model_predictions_feature_group_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x1b459a823d0>, None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_group.insert(predictions, write_options={\"wait_for_job\": False})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
